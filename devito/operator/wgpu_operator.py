from math import prod
import timeit
from typing import cast
from devito import Operator
from devito.ir.ietxdsl import transform_devito_to_iet_ssa, iet_to_standard_mlir, finalize_module_with_globals
from devito.logger import perf

import os
import tempfile
import subprocess
import ctypes
import numpy as np
import wgpu

from collections import OrderedDict
from io import StringIO

from devito.exceptions import InvalidOperator
from devito.logger import perf, info
from devito.ir.iet import Callable, MetaCall
from devito.ir.support import SymbolRegistry
from devito.operator.operator import IRs
from devito.operator.profiling import create_profile
from devito.tools import OrderedSet, as_tuple, flatten, filter_sorted
from devito.types import Evaluable, TimeFunction
from devito.types.mlir_types import ptr_of, f32

from mpi4py import MPI

from xdsl.ir import MLContext
from xdsl.tools.command_line_tool import get_all_dialects
from xdsl.passes import ModulePass
from xdsl.transforms.experimental.stencil_shape_inference import StencilShapeInferencePass
from xdsl.transforms.experimental.convert_stencil_to_ll_mlir import ConvertStencilToLLMLIRPass
from xdsl.transforms.reconcile_unrealized_casts import ReconcileUnrealizedCastsPass
from xdsl.transforms.mlir_opt import MLIROptPass

from xdsl.dialects.builtin import ModuleOp, SymbolRefAttr
from xdsl.traits import SymbolTable

from xdsl.interpreter import Interpreter
from xdsl.interpreters.experimental.wgpu import WGPUFunctions
from xdsl.interpreters.scf import ScfFunctions
from xdsl.interpreters.arith import ArithFunctions
from xdsl.interpreters.func import FuncFunctions

__all__ = ['XDSLOperator']



MLIR_GPU_PIPELINE = lambda block_sizes: f'builtin.module(test-math-algebraic-simplification,scf-parallel-loop-tiling{{parallel-loop-tile-sizes={block_sizes}}},func.func(gpu-map-parallel-loops),convert-parallel-loops-to-gpu,lower-affine, canonicalize,cse, fold-memref-alias-ops, gpu-launch-sink-index-computations, gpu-kernel-outlining, canonicalize{{region-simplify}},cse,fold-memref-alias-ops,expand-strided-metadata,lower-affine,canonicalize,cse)'

XDSL_GPU_PIPELINE = "stencil-shape-inference,convert-stencil-to-ll-mlir{target=gpu},reconcile-unrealized-casts,printf-to-llvm"


class WGPUOperator(Operator):

    def __new__(cls, expressions, **kwargs):
        self = super(WGPUOperator, cls).__new__(cls, expressions, **kwargs)
        self.ctx = MLContext()
        for d in get_all_dialects():
            self.ctx.register_dialect(d)
        self.__class__ = cls
        return self

    @property
    def mpi_shape(self) -> tuple:
        dist = self.functions[0].grid.distributor
        # temporary fix:
        # swap dim 0 and 1 in topology because dmp.grid is row major and not column major

        return (dist.topology[1], dist.topology[0], *dist.topology[2:]), dist.myrank

    def _jit_compile(self):
        """
        JIT-compile the C code generated by the Operator.
        It is ensured that JIT compilation will only be performed once per
        Operator, reagardless of how many times this method is invoked.
        """
        #ccode = transform_devito_xdsl_string(self)
        #self.ccode = ccode
        with self._profiler.timer_on('jit-compile'):

            # specialize the code for the specific apply parameters
            finalize_module_with_globals(self._module, self._jit_kernel_constants, gpu_boilerplate=False)

            to_tile = len(list(filter(lambda s : str(s) in ["x", "y", "z"], self.dimensions)))-1


            block_sizes: list[int] = [min(target, self._jit_kernel_constants.get(f"{dim}_size", 1)) for target, dim in zip([32, 4, 8], ["x", "y", "z"])]
            block_sizes = ','.join(str(bs) for bs in block_sizes)

            xdsl_pipeline = XDSL_GPU_PIPELINE
            mlir_pipeline = MLIR_GPU_PIPELINE(block_sizes)
            
            xdsl_passes : tuple[ModulePass, ...] = (StencilShapeInferencePass(), ConvertStencilToLLMLIRPass('gpu'), MLIROptPass(['-p', mlir_pipeline, '--mlir-print-op-generic']))
            for p in xdsl_passes:
                p.apply(self.ctx, self._module)
            
            interpreter = Interpreter(self._module)
            interpreter.register_implementations(wgpuf := WGPUFunctions())
            interpreter.register_implementations(ScfFunctions())
            interpreter.register_implementations(ArithFunctions())
            interpreter.register_implementations(FuncFunctions())

            assert isinstance(self._module, ModuleOp)
            func = SymbolTable.lookup_symbol(self._module, "apply_kernel")
            assert func is not None

            def f(*args, **kwargs):
                gpuargs = []
                for a in args[:-1]:
                    buf = wgpuf.device.create_buffer(size=a.nbytes, usage= wgpu.BufferUsage.STORAGE  # pyright: ignore
                | wgpu.BufferUsage.COPY_DST  # pyright: ignore
                | wgpu.BufferUsage.COPY_SRC)  # pyright: ignore)
                    wgpuf.device.queue.write_buffer(buf, 0, a)
                    gpuargs.append(buf)
                with self._profiler.timer_on('wgpu-apply'):
                    res = interpreter.run_ssacfg_region(func.body, gpuargs)
                e = self._profiler.py_timers['wgpu-apply']
                c_double_p = ctypes.POINTER(ctypes.c_double)
                ctypes.cast(args[-1], c_double_p).contents.value = e
                for i, g in enumerate(gpuargs):
                    view = wgpuf.device.queue.read_buffer(g)
                    
                    np.copyto(args[i], view.cast('f', args[i].shape))

                return
            
            self._cfunction = f

        elapsed = self._profiler.py_timers['jit-compile']

        perf("WGPUOperator `%s` jit-compiled in %.2f s with `mlir-opt`" %
             (self.name, elapsed))

    def _construct_cfunction_args(self, args):
        """
        Either construct the args for the cfunction, or construct the
        arg types for it.
        """
        """
        Add memrefs to args dictionary so they can be passed to the cfunction
        """
        cargs = dict()
        for arg in self.functions:
            if isinstance(arg, TimeFunction):
                data = arg._data_allocated
                # iterate over the first dimension (time)
                for t in range(data.shape[0]):
                    cargs[f'{arg._C_name}_{t}'] = data[t, ...]
        cargs['timers'] = args['timers']
        return cargs.values()
        

    @property
    def cfunction(self):
        """The JIT-compiled C function as a ctypes.FuncPtr object."""
        if self._cfunction is None:
            self._jit_compile()
        return self._cfunction

    @classmethod
    def _lower(cls, expressions, **kwargs):
        """
        Perform the lowering Expressions -> Clusters -> ScheduleTree -> IET.
        """
        # Create a symbol registry
        kwargs['sregistry'] = SymbolRegistry()

        expressions = as_tuple(expressions)

        # Input check
        if any(not isinstance(i, Evaluable) for i in expressions):
            raise InvalidOperator("Only `devito.Evaluable` are allowed.")

        # Enable recursive lowering
        # This may be used by a compilation pass that constructs a new
        # expression for which a partial or complete lowering is desired
        kwargs['lower'] = cls._lower

        # [Eq] -> [LoweredEq]
        expressions = cls._lower_exprs(expressions, **kwargs)

        from devito.ir.ietxdsl.cluster_to_ssa import ExtractDevitoStencilConversion, convert_devito_stencil_to_xdsl_stencil
        conv = ExtractDevitoStencilConversion(expressions)
        module = conv.convert()
        convert_devito_stencil_to_xdsl_stencil(module, timed=False)

        # [LoweredEq] -> [Clusters]
        clusters = cls._lower_clusters(expressions, **kwargs)

        # [Clusters] -> ScheduleTree
        stree = cls._lower_stree(clusters, **kwargs)

        # ScheduleTree -> unbounded IET
        uiet = cls._lower_uiet(stree, **kwargs)

        # unbounded IET -> IET
        iet, byproduct = cls._lower_iet(uiet, **kwargs)

        return IRs(expressions, clusters, stree, uiet, iet), byproduct, module


    @classmethod
    def _build(cls, expressions, **kwargs) -> Callable:
        # Python- (i.e., compile-) and C-level (i.e., run-time) performance
        profiler = create_profile('timers')

        # Lower the input expressions into an IET
        irs, byproduct, module = cls._lower(expressions, profiler=profiler, **kwargs)

        # Make it an actual Operator
        op = Callable.__new__(cls, **irs.iet.args)
        Callable.__init__(op, **op.args)

        # Header files, etc.
        op._headers = OrderedSet(*cls._default_headers)
        op._headers.update(byproduct.headers)
        op._globals = OrderedSet(*cls._default_globals)
        op._includes = OrderedSet(*cls._default_includes)
        op._includes.update(profiler._default_includes)
        op._includes.update(byproduct.includes)
        op._module = module

        # Required for the jit-compilation
        op._compiler = kwargs['compiler']
        op._lib = None
        op._cfunction = None

        # Potentially required for lazily allocated Functions
        op._mode = kwargs['mode']
        op._options = kwargs['options']
        op._allocator = kwargs['allocator']
        op._platform = kwargs['platform']

        # References to local or external routines
        op._func_table = OrderedDict()
        op._func_table.update(OrderedDict([(i, MetaCall(None, False))
                                           for i in profiler._ext_calls]))
        op._func_table.update(OrderedDict([(i.root.name, i) for i in byproduct.funcs]))

        # Internal mutable state to store information about previous runs, autotuning
        # reports, etc
        op._state = cls._initialize_state(**kwargs)

        # Produced by the various compilation passes
        op._reads = filter_sorted(flatten(e.reads for e in irs.expressions))
        op._writes = filter_sorted(flatten(e.writes for e in irs.expressions))
        op._dimensions = set().union(*[e.dimensions for e in irs.expressions])
        op._dtype, op._dspace = irs.clusters.meta
        op._profiler = profiler

        return op

    @property
    def mlircode(self):
        from xdsl.printer import Printer
        from io import StringIO
        file = StringIO()
        Printer(file).print(self._module)
        return file.getvalue()

def get_arg_names_from_module(op):
    return [
        str_attr.data 
        for str_attr in op.body.block.ops.first.attributes['param_names'].data
    ]
